{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import sys\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance, distance_matrix\n",
    "import random as rd\n",
    "\n",
    "import matplotlib \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## build perspective matrix list for all images for drift&distortion correction\n",
    "def get_perspective_matrix(img1, img2, MIN_MATCH_COUNT = 10, plot = False):\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "        img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "    else:\n",
    "        print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        matchesMask = None\n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                           singlePointColor = None,\n",
    "                           matchesMask = matchesMask, # draw only inliers\n",
    "                           flags = 2)\n",
    "        img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "        plt.imshow(img3, 'gray'),plt.show()\n",
    "    return M\n",
    "\n",
    "def matrix_shift_after_perspective(shift_x, shift_y, perspective_matrix):\n",
    "    translation_matrix = np.float32([[1,0,shift_y], [0,1,shift_x], [0,0,1]])\n",
    "    return np.dot(translation_matrix,M)\n",
    "\n",
    "############################## find warp matrix for each image, apply to each images\n",
    "\n",
    "perspective_0 = np.float32(np.identity(3)) \n",
    "perspective_matrixes = [perspective_0]\n",
    "for num_mapping in range(8):\n",
    "    img1 = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping}.jpeg',0)[:,:]          # queryImage\n",
    "    img2 = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping+1}.jpeg',0)[:,:]          # trainImage\n",
    "    M = get_perspective_matrix(img2, img1)\n",
    "    perspective_matrixes.append(M)\n",
    "    \n",
    "for i in range(1, len(perspective_matrixes)):\n",
    "    perspective_matrixes[i] = np.dot(perspective_matrixes[i-1],perspective_matrixes[i])\n",
    "\n",
    "############################## save warped confid images in a stack\n",
    "\n",
    "image=[]\n",
    "for num_mapping in range(8):\n",
    "    img = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping}.jpeg',0)\n",
    "    if num_mapping == 3:\n",
    "        img = cv2.copyMakeBorder(img, 0,100,0,100, cv2.BORDER_CONSTANT, value = 0)\n",
    "    else:\n",
    "        img = cv2.warpPerspective(img, perspective_matrixes[num_mapping], (500,500))\n",
    "    image.append(img)\n",
    "image = np.array(image)\n",
    "tif.imsave(f'data/index_mapping_confid_warp.tif', image)\n",
    "\n",
    "################################  perspective matrix list save in perspective_matrixes\n",
    "perspective_matrixes = np.array(perspective_matrixes)\n",
    "np.save(f'data/perspective_matrixes.npy', perspective_matrixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
