{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import sys\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance, distance_matrix\n",
    "import random as rd\n",
    "\n",
    "import matplotlib \n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distortion correction using perspective model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## build perspective matrix list for all images for drift&distortion correction\n",
    "def get_perspective_matrix(img1, img2, MIN_MATCH_COUNT = 10, plot = False):\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "        img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "    else:\n",
    "        print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        matchesMask = None\n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                           singlePointColor = None,\n",
    "                           matchesMask = matchesMask, # draw only inliers\n",
    "                           flags = 2)\n",
    "        img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "        plt.imshow(img3, 'gray'),plt.show()\n",
    "    return M\n",
    "\n",
    "def matrix_shift_after_perspective(shift_x, shift_y, perspective_matrix):\n",
    "    translation_matrix = np.float32([[1,0,shift_y], [0,1,shift_x], [0,0,1]])\n",
    "    return np.dot(translation_matrix,M)\n",
    "\n",
    "############################## find warp matrix for each image, apply to each images\n",
    "\n",
    "perspective_0 = np.float32(np.identity(3)) \n",
    "perspective_matrixes = [perspective_0]\n",
    "for num_mapping in range(8):\n",
    "    img1 = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping}.jpeg',0)[:,:]          # queryImage\n",
    "    img2 = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping+1}.jpeg',0)[:,:]          # trainImage\n",
    "    M = get_perspective_matrix(img2, img1)\n",
    "    perspective_matrixes.append(M)\n",
    "    \n",
    "for i in range(1, len(perspective_matrixes)):\n",
    "    perspective_matrixes[i] = np.dot(perspective_matrixes[i-1],perspective_matrixes[i])\n",
    "\n",
    "############################## save warped confid images in a stack\n",
    "\n",
    "image=[]\n",
    "for num_mapping in range(8):\n",
    "    img = cv2.imread(f'data/index_mapping_confid_origin_{num_mapping}.jpeg',0)\n",
    "    if num_mapping == 3:\n",
    "        img = cv2.copyMakeBorder(img, 0,100,0,100, cv2.BORDER_CONSTANT, value = 0)\n",
    "    else:\n",
    "        img = cv2.warpPerspective(img, perspective_matrixes[num_mapping], (500,500))\n",
    "    image.append(img)\n",
    "image = np.array(image)\n",
    "tif.imsave(f'data/index_mapping_confid_warp.tif', image)\n",
    "\n",
    "################################  perspective matrix list save in perspective_matrixes\n",
    "perspective_matrixes = np.array(perspective_matrixes)\n",
    "np.save(f'data/perspective_matrixes.npy', perspective_matrixes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distortion correction using non-linear elastic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "def read_xy(file_path):\n",
    "    start_line = \"X Trans -----------------------------------\"  # Replace with the actual start line\n",
    "    end_line = \"Y Trans -----------------------------------\"  # Replace with the actual end line\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Initialize variables\n",
    "        start_found = False\n",
    "        content = []\n",
    "\n",
    "        # Iterate over the lines in the file\n",
    "        for line in file:\n",
    "            # Check if the start line is found\n",
    "            if start_line in line:\n",
    "                start_found = True\n",
    "                continue\n",
    "\n",
    "            # Check if the end line is found\n",
    "            if end_line in line:\n",
    "                break\n",
    "\n",
    "            # If the start line is found and the end line is not found, capture the content\n",
    "            if start_found:\n",
    "                content.append(line)\n",
    "\n",
    "    # Join the captured content into a single string\n",
    "    content_str_x = ''.join(content)\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Initialize variables\n",
    "        start_found = False\n",
    "        content = []\n",
    "\n",
    "        # Iterate over the lines in the file\n",
    "        for line in file:\n",
    "            # Check if the start line is found\n",
    "            if end_line in line:\n",
    "                start_found = True\n",
    "                continue\n",
    "\n",
    "            # If the start line is found and the end line is not found, capture the content\n",
    "            if start_found:\n",
    "                content.append(line)\n",
    "\n",
    "    # Join the captured content into a single string\n",
    "    content_str_y = ''.join(content)\n",
    "    \n",
    "    return content_str_x, content_str_y\n",
    "\n",
    "def get_locs(content_str_x, content_str_y):\n",
    "    array_y = np.fromstring(content_str_y, dtype=float, sep=' ')\n",
    "    array_x = np.fromstring(content_str_x, dtype=float, sep=' ')\n",
    "    new_loc = np.vstack((array_y, array_x)).T\n",
    "    new_loc = new_loc.reshape(400,400,2)\n",
    "    return new_loc\n",
    "\n",
    "def image_deform(img, new_loc):\n",
    "    new_image = np.zeros((img.shape[0], img.shape[1], 3), np.uint8)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            x = int(new_loc[i][j][0])\n",
    "            y = int(new_loc[i][j][1])\n",
    "            if 0 <= x < 400 and 0 <= y < 400:\n",
    "                new_image[i][j] = img[x][y]\n",
    "    return new_image\n",
    "\n",
    "# register 4d-stem data to frame 5\n",
    "from tqdm import tqdm\n",
    "frame_1 = 5\n",
    "frame_2 = 9\n",
    "    \n",
    "import hyperspy.api as hs\n",
    "data_file = hs.load(f\"data/{frame_2}.hspy\")\n",
    "data_corrected = np.zeros([data_file.data.shape[0],data_file.data.shape[1],120,120])\n",
    "file_path = f'registration/{frame_1}-{frame_2}_raw.txt'\n",
    "content_str_x, content_str_y = read_xy(file_path)\n",
    "new_loc = get_locs(content_str_x, content_str_y)\n",
    "print(\"shift\", new_loc[0][0])\n",
    "\n",
    "for i in tqdm(range(data_file.data.shape[0])):\n",
    "    for j in range(data_file.data.shape[1]):\n",
    "        x = int(new_loc[i][j][0])\n",
    "        y = int(new_loc[i][j][1])\n",
    "        if 0 <= x < 400 and 0 <= y < 400:\n",
    "            data_corrected[i,j] = np.array(data_file.inav[x,y].data)\n",
    "\n",
    "data_corrected = hs.signals.Signal2D(data_corrected)\n",
    "data_corrected.save(f\"data/{frame_2}_corrected.hspy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
